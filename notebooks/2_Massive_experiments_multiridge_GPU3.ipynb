{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09d7dab7-856f-41bf-982e-3bf2ecd98fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "sys.path.append('..')\n",
    "from src.utils import *\n",
    "from src.models import *\n",
    "from src.configs import *\n",
    "\n",
    "\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "rcParams.update(fig_params)\n",
    "\n",
    "import warnings\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c7d52f-0a18-485d-acb3-a5a267aaff88",
   "metadata": {},
   "source": [
    "## Set device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38188f08-09c1-4ac4-ade7-3263260da148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:3\n"
     ]
    }
   ],
   "source": [
    "DEVICE = 'cuda:3' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using device:', DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c875d9fb-452b-4a0d-bf82-91f0bec435d2",
   "metadata": {},
   "source": [
    "## Load experiments file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96d865ad-54bd-4625-af55-8f42d608dcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME = 'Experiments_MASSIVE.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "656333c9-0550-4849-bceb-abb9fae99313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exp_id</th>\n",
       "      <th>seed</th>\n",
       "      <th>torch_dtype</th>\n",
       "      <th>samples_number</th>\n",
       "      <th>features_number</th>\n",
       "      <th>snr_db</th>\n",
       "      <th>informative_frac</th>\n",
       "      <th>folds_number</th>\n",
       "      <th>initialization</th>\n",
       "      <th>epochs_number</th>\n",
       "      <th>learning_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MASSIVE000</td>\n",
       "      <td>8925</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MASSIVE001</td>\n",
       "      <td>65459</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MASSIVE002</td>\n",
       "      <td>30300</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MASSIVE003</td>\n",
       "      <td>38747</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MASSIVE004</td>\n",
       "      <td>26932</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       exp_id   seed  torch_dtype  samples_number  features_number  snr_db  \\\n",
       "0  MASSIVE000   8925           64            1000              100      20   \n",
       "1  MASSIVE001  65459           64            1000              100      20   \n",
       "2  MASSIVE002  30300           64            1000              100      20   \n",
       "3  MASSIVE003  38747           64            1000              100      20   \n",
       "4  MASSIVE004  26932           64            1000              100      20   \n",
       "\n",
       "   informative_frac  folds_number  initialization  epochs_number  \\\n",
       "0               0.5             5             1.0            300   \n",
       "1               0.5             5             1.0            300   \n",
       "2               0.5             5             1.0            300   \n",
       "3               0.5             5             1.0            300   \n",
       "4               0.5             5             1.0            300   \n",
       "\n",
       "   learning_rate  \n",
       "0          350.0  \n",
       "1          350.0  \n",
       "2          350.0  \n",
       "3          350.0  \n",
       "4          350.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_df = pd.read_excel(os.path.join('..', 'experiments', FILENAME), dtype=FORMAT)\n",
    "exp_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8369c02c-e9df-47cf-9a2d-dcfa7b2757da",
   "metadata": {},
   "source": [
    "## Run experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71338711-47c9-4895-907c-7a237a7fa417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exp_id</th>\n",
       "      <th>seed</th>\n",
       "      <th>torch_dtype</th>\n",
       "      <th>samples_number</th>\n",
       "      <th>features_number</th>\n",
       "      <th>snr_db</th>\n",
       "      <th>informative_frac</th>\n",
       "      <th>folds_number</th>\n",
       "      <th>initialization</th>\n",
       "      <th>epochs_number</th>\n",
       "      <th>learning_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>MASSIVE100</td>\n",
       "      <td>47464</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>1100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>MASSIVE101</td>\n",
       "      <td>57137</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>1100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>MASSIVE102</td>\n",
       "      <td>41965</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>1100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>MASSIVE103</td>\n",
       "      <td>12476</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>1100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>MASSIVE104</td>\n",
       "      <td>57991</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>1100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>MASSIVE105</td>\n",
       "      <td>32831</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>1100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>MASSIVE106</td>\n",
       "      <td>43424</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>1100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>MASSIVE107</td>\n",
       "      <td>91048</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>1100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>MASSIVE108</td>\n",
       "      <td>35536</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>1100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>MASSIVE109</td>\n",
       "      <td>99629</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>1100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>MASSIVE110</td>\n",
       "      <td>176</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>1200</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>MASSIVE111</td>\n",
       "      <td>33990</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>1200</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>MASSIVE112</td>\n",
       "      <td>81423</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>1200</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>MASSIVE113</td>\n",
       "      <td>67735</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>1200</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>MASSIVE114</td>\n",
       "      <td>4889</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>1200</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>MASSIVE115</td>\n",
       "      <td>57289</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>1200</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>MASSIVE116</td>\n",
       "      <td>92807</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>1200</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>MASSIVE117</td>\n",
       "      <td>11701</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>1200</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>MASSIVE118</td>\n",
       "      <td>23246</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>1200</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>MASSIVE119</td>\n",
       "      <td>36371</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>1200</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>MASSIVE120</td>\n",
       "      <td>96257</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>1300</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>MASSIVE121</td>\n",
       "      <td>68232</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>1300</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>MASSIVE122</td>\n",
       "      <td>96090</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>1300</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>MASSIVE123</td>\n",
       "      <td>80418</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>1300</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>MASSIVE124</td>\n",
       "      <td>44059</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>1300</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>MASSIVE125</td>\n",
       "      <td>17842</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>1300</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>MASSIVE126</td>\n",
       "      <td>93639</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>1300</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>MASSIVE127</td>\n",
       "      <td>73120</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>1300</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>MASSIVE128</td>\n",
       "      <td>82840</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>1300</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>MASSIVE129</td>\n",
       "      <td>40784</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>1300</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>MASSIVE130</td>\n",
       "      <td>62496</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>1400</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>MASSIVE131</td>\n",
       "      <td>17063</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>1400</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>MASSIVE132</td>\n",
       "      <td>58235</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>1400</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>MASSIVE133</td>\n",
       "      <td>86544</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>1400</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>MASSIVE134</td>\n",
       "      <td>30268</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>1400</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>MASSIVE135</td>\n",
       "      <td>4312</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>1400</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>MASSIVE136</td>\n",
       "      <td>84564</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>1400</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>MASSIVE137</td>\n",
       "      <td>76526</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>1400</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>MASSIVE138</td>\n",
       "      <td>54059</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>1400</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>MASSIVE139</td>\n",
       "      <td>79857</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>1400</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         exp_id   seed  torch_dtype  samples_number  features_number  snr_db  \\\n",
       "100  MASSIVE100  47464           64            1000             1100      20   \n",
       "101  MASSIVE101  57137           64            1000             1100      20   \n",
       "102  MASSIVE102  41965           64            1000             1100      20   \n",
       "103  MASSIVE103  12476           64            1000             1100      20   \n",
       "104  MASSIVE104  57991           64            1000             1100      20   \n",
       "105  MASSIVE105  32831           64            1000             1100      20   \n",
       "106  MASSIVE106  43424           64            1000             1100      20   \n",
       "107  MASSIVE107  91048           64            1000             1100      20   \n",
       "108  MASSIVE108  35536           64            1000             1100      20   \n",
       "109  MASSIVE109  99629           64            1000             1100      20   \n",
       "110  MASSIVE110    176           64            1000             1200      20   \n",
       "111  MASSIVE111  33990           64            1000             1200      20   \n",
       "112  MASSIVE112  81423           64            1000             1200      20   \n",
       "113  MASSIVE113  67735           64            1000             1200      20   \n",
       "114  MASSIVE114   4889           64            1000             1200      20   \n",
       "115  MASSIVE115  57289           64            1000             1200      20   \n",
       "116  MASSIVE116  92807           64            1000             1200      20   \n",
       "117  MASSIVE117  11701           64            1000             1200      20   \n",
       "118  MASSIVE118  23246           64            1000             1200      20   \n",
       "119  MASSIVE119  36371           64            1000             1200      20   \n",
       "120  MASSIVE120  96257           64            1000             1300      20   \n",
       "121  MASSIVE121  68232           64            1000             1300      20   \n",
       "122  MASSIVE122  96090           64            1000             1300      20   \n",
       "123  MASSIVE123  80418           64            1000             1300      20   \n",
       "124  MASSIVE124  44059           64            1000             1300      20   \n",
       "125  MASSIVE125  17842           64            1000             1300      20   \n",
       "126  MASSIVE126  93639           64            1000             1300      20   \n",
       "127  MASSIVE127  73120           64            1000             1300      20   \n",
       "128  MASSIVE128  82840           64            1000             1300      20   \n",
       "129  MASSIVE129  40784           64            1000             1300      20   \n",
       "130  MASSIVE130  62496           64            1000             1400      20   \n",
       "131  MASSIVE131  17063           64            1000             1400      20   \n",
       "132  MASSIVE132  58235           64            1000             1400      20   \n",
       "133  MASSIVE133  86544           64            1000             1400      20   \n",
       "134  MASSIVE134  30268           64            1000             1400      20   \n",
       "135  MASSIVE135   4312           64            1000             1400      20   \n",
       "136  MASSIVE136  84564           64            1000             1400      20   \n",
       "137  MASSIVE137  76526           64            1000             1400      20   \n",
       "138  MASSIVE138  54059           64            1000             1400      20   \n",
       "139  MASSIVE139  79857           64            1000             1400      20   \n",
       "\n",
       "     informative_frac  folds_number  initialization  epochs_number  \\\n",
       "100               0.5             5             1.0            300   \n",
       "101               0.5             5             1.0            300   \n",
       "102               0.5             5             1.0            300   \n",
       "103               0.5             5             1.0            300   \n",
       "104               0.5             5             1.0            300   \n",
       "105               0.5             5             1.0            300   \n",
       "106               0.5             5             1.0            300   \n",
       "107               0.5             5             1.0            300   \n",
       "108               0.5             5             1.0            300   \n",
       "109               0.5             5             1.0            300   \n",
       "110               0.5             5             1.0            300   \n",
       "111               0.5             5             1.0            300   \n",
       "112               0.5             5             1.0            300   \n",
       "113               0.5             5             1.0            300   \n",
       "114               0.5             5             1.0            300   \n",
       "115               0.5             5             1.0            300   \n",
       "116               0.5             5             1.0            300   \n",
       "117               0.5             5             1.0            300   \n",
       "118               0.5             5             1.0            300   \n",
       "119               0.5             5             1.0            300   \n",
       "120               0.5             5             1.0            300   \n",
       "121               0.5             5             1.0            300   \n",
       "122               0.5             5             1.0            300   \n",
       "123               0.5             5             1.0            300   \n",
       "124               0.5             5             1.0            300   \n",
       "125               0.5             5             1.0            300   \n",
       "126               0.5             5             1.0            300   \n",
       "127               0.5             5             1.0            300   \n",
       "128               0.5             5             1.0            300   \n",
       "129               0.5             5             1.0            300   \n",
       "130               0.5             5             1.0            300   \n",
       "131               0.5             5             1.0            300   \n",
       "132               0.5             5             1.0            300   \n",
       "133               0.5             5             1.0            300   \n",
       "134               0.5             5             1.0            300   \n",
       "135               0.5             5             1.0            300   \n",
       "136               0.5             5             1.0            300   \n",
       "137               0.5             5             1.0            300   \n",
       "138               0.5             5             1.0            300   \n",
       "139               0.5             5             1.0            300   \n",
       "\n",
       "     learning_rate  \n",
       "100          350.0  \n",
       "101          350.0  \n",
       "102          350.0  \n",
       "103          350.0  \n",
       "104          350.0  \n",
       "105          350.0  \n",
       "106          350.0  \n",
       "107          350.0  \n",
       "108          350.0  \n",
       "109          350.0  \n",
       "110          350.0  \n",
       "111          350.0  \n",
       "112          350.0  \n",
       "113          350.0  \n",
       "114          350.0  \n",
       "115          350.0  \n",
       "116          350.0  \n",
       "117          350.0  \n",
       "118          350.0  \n",
       "119          350.0  \n",
       "120          350.0  \n",
       "121          350.0  \n",
       "122          350.0  \n",
       "123          350.0  \n",
       "124          350.0  \n",
       "125          350.0  \n",
       "126          350.0  \n",
       "127          350.0  \n",
       "128          350.0  \n",
       "129          350.0  \n",
       "130          350.0  \n",
       "131          350.0  \n",
       "132          350.0  \n",
       "133          350.0  \n",
       "134          350.0  \n",
       "135          350.0  \n",
       "136          350.0  \n",
       "137          350.0  \n",
       "138          350.0  \n",
       "139          350.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_df = exp_df.iloc[100:].copy()\n",
    "exp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8262a1f-3512-4e5d-af16-34d0ac51d38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: Train r2: 0.990, Valid r2: 0.925, Test r2: 0.923, Train mse: 0.010, Valid mse: 0.074, Test mse: 0.077\n",
      "Epoch 41: Train r2: 0.987, Valid r2: 0.906, Test r2: 0.919, Train mse: 0.013, Valid mse: 0.094, Test mse: 0.081\n",
      "Epoch 51: Train r2: 0.990, Valid r2: 0.931, Test r2: 0.927, Train mse: 0.010, Valid mse: 0.068, Test mse: 0.073\n",
      "Epoch 61: Train r2: 0.992, Valid r2: 0.941, Test r2: 0.939, Train mse: 0.008, Valid mse: 0.058, Test mse: 0.062\n",
      "Epoch 71: Train r2: 0.991, Valid r2: 0.932, Test r2: 0.939, Train mse: 0.009, Valid mse: 0.068, Test mse: 0.062\n",
      "Epoch 81: Train r2: 0.990, Valid r2: 0.926, Test r2: 0.936, Train mse: 0.010, Valid mse: 0.073, Test mse: 0.064\n",
      "Epoch 91: Train r2: 0.991, Valid r2: 0.927, Test r2: 0.936, Train mse: 0.009, Valid mse: 0.072, Test mse: 0.064\n",
      "Epoch 101: Train r2: 0.991, Valid r2: 0.929, Test r2: 0.944, Train mse: 0.009, Valid mse: 0.072, Test mse: 0.057\n",
      "Epoch 111: Train r2: 0.993, Valid r2: 0.947, Test r2: 0.949, Train mse: 0.007, Valid mse: 0.052, Test mse: 0.051\n",
      "Epoch 121: Train r2: 0.995, Valid r2: 0.959, Test r2: 0.955, Train mse: 0.005, Valid mse: 0.040, Test mse: 0.045\n",
      "Epoch 131: Train r2: 0.995, Valid r2: 0.957, Test r2: 0.957, Train mse: 0.005, Valid mse: 0.042, Test mse: 0.044\n",
      "Epoch 141: Train r2: 0.992, Valid r2: 0.941, Test r2: 0.948, Train mse: 0.008, Valid mse: 0.058, Test mse: 0.052\n",
      "Epoch 151: Train r2: 0.992, Valid r2: 0.936, Test r2: 0.947, Train mse: 0.008, Valid mse: 0.063, Test mse: 0.053\n",
      "Epoch 161: Train r2: 0.994, Valid r2: 0.954, Test r2: 0.951, Train mse: 0.006, Valid mse: 0.046, Test mse: 0.049\n",
      "Epoch 171: Train r2: 0.991, Valid r2: 0.934, Test r2: 0.939, Train mse: 0.009, Valid mse: 0.065, Test mse: 0.062\n",
      "Epoch 181: Train r2: 0.993, Valid r2: 0.947, Test r2: 0.945, Train mse: 0.007, Valid mse: 0.053, Test mse: 0.055\n",
      "Epoch 191: Train r2: 0.995, Valid r2: 0.960, Test r2: 0.957, Train mse: 0.005, Valid mse: 0.039, Test mse: 0.044\n",
      "Epoch 201: Train r2: 0.993, Valid r2: 0.948, Test r2: 0.951, Train mse: 0.007, Valid mse: 0.051, Test mse: 0.049\n",
      "Epoch 211: Train r2: 0.996, Valid r2: 0.965, Test r2: 0.960, Train mse: 0.004, Valid mse: 0.035, Test mse: 0.040\n",
      "Epoch 221: Train r2: 0.996, Valid r2: 0.971, Test r2: 0.957, Train mse: 0.004, Valid mse: 0.029, Test mse: 0.043\n",
      "Epoch 231: Train r2: 0.992, Valid r2: 0.937, Test r2: 0.942, Train mse: 0.008, Valid mse: 0.062, Test mse: 0.058\n",
      "Epoch 241: Train r2: 0.995, Valid r2: 0.959, Test r2: 0.954, Train mse: 0.005, Valid mse: 0.040, Test mse: 0.046\n",
      "Epoch 251: Train r2: 0.997, Valid r2: 0.973, Test r2: 0.964, Train mse: 0.003, Valid mse: 0.026, Test mse: 0.036\n",
      "Epoch 261: Train r2: 0.997, Valid r2: 0.977, Test r2: 0.962, Train mse: 0.003, Valid mse: 0.023, Test mse: 0.039\n",
      "Epoch 271: Train r2: 0.998, Valid r2: 0.979, Test r2: 0.964, Train mse: 0.002, Valid mse: 0.021, Test mse: 0.036\n",
      "Epoch 281: Train r2: 0.997, Valid r2: 0.975, Test r2: 0.960, Train mse: 0.003, Valid mse: 0.024, Test mse: 0.040\n",
      "Epoch 291: Train r2: 0.996, Valid r2: 0.967, Test r2: 0.960, Train mse: 0.004, Valid mse: 0.033, Test mse: 0.040\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4fb300f3b6149a485c4bbfbbb4eb360",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train r2: 0.856, Valid r2: 0.483, Test r2: 0.528, Train mse: 0.144, Valid mse: 0.518, Test mse: 0.469\n",
      "Epoch 11: Train r2: 0.988, Valid r2: 0.914, Test r2: 0.891, Train mse: 0.012, Valid mse: 0.085, Test mse: 0.108\n",
      "Epoch 21: Train r2: 0.990, Valid r2: 0.923, Test r2: 0.916, Train mse: 0.010, Valid mse: 0.076, Test mse: 0.083\n",
      "Epoch 31: Train r2: 0.990, Valid r2: 0.916, Test r2: 0.925, Train mse: 0.010, Valid mse: 0.083, Test mse: 0.075\n",
      "Epoch 41: Train r2: 0.990, Valid r2: 0.931, Test r2: 0.930, Train mse: 0.010, Valid mse: 0.069, Test mse: 0.070\n",
      "Epoch 51: Train r2: 0.991, Valid r2: 0.937, Test r2: 0.938, Train mse: 0.009, Valid mse: 0.062, Test mse: 0.062\n",
      "Epoch 61: Train r2: 0.990, Valid r2: 0.928, Test r2: 0.931, Train mse: 0.010, Valid mse: 0.071, Test mse: 0.069\n",
      "Epoch 71: Train r2: 0.992, Valid r2: 0.946, Test r2: 0.943, Train mse: 0.008, Valid mse: 0.053, Test mse: 0.057\n",
      "Epoch 81: Train r2: 0.991, Valid r2: 0.932, Test r2: 0.933, Train mse: 0.009, Valid mse: 0.067, Test mse: 0.067\n",
      "Epoch 91: Train r2: 0.992, Valid r2: 0.934, Test r2: 0.942, Train mse: 0.008, Valid mse: 0.065, Test mse: 0.058\n",
      "Epoch 101: Train r2: 0.994, Valid r2: 0.950, Test r2: 0.946, Train mse: 0.006, Valid mse: 0.050, Test mse: 0.053\n",
      "Epoch 111: Train r2: 0.993, Valid r2: 0.949, Test r2: 0.940, Train mse: 0.007, Valid mse: 0.050, Test mse: 0.060\n",
      "Epoch 121: Train r2: 0.994, Valid r2: 0.953, Test r2: 0.946, Train mse: 0.006, Valid mse: 0.046, Test mse: 0.054\n",
      "Epoch 131: Train r2: 0.992, Valid r2: 0.939, Test r2: 0.934, Train mse: 0.008, Valid mse: 0.061, Test mse: 0.066\n",
      "Epoch 141: Train r2: 0.992, Valid r2: 0.938, Test r2: 0.938, Train mse: 0.008, Valid mse: 0.062, Test mse: 0.061\n",
      "Epoch 151: Train r2: 0.995, Valid r2: 0.957, Test r2: 0.947, Train mse: 0.005, Valid mse: 0.043, Test mse: 0.053\n",
      "Epoch 161: Train r2: 0.994, Valid r2: 0.955, Test r2: 0.946, Train mse: 0.006, Valid mse: 0.045, Test mse: 0.053\n",
      "Epoch 171: Train r2: 0.995, Valid r2: 0.965, Test r2: 0.952, Train mse: 0.005, Valid mse: 0.035, Test mse: 0.048\n",
      "Epoch 181: Train r2: 0.994, Valid r2: 0.956, Test r2: 0.950, Train mse: 0.006, Valid mse: 0.044, Test mse: 0.050\n",
      "Epoch 191: Train r2: 0.994, Valid r2: 0.958, Test r2: 0.950, Train mse: 0.006, Valid mse: 0.042, Test mse: 0.050\n",
      "Epoch 201: Train r2: 0.995, Valid r2: 0.967, Test r2: 0.953, Train mse: 0.005, Valid mse: 0.033, Test mse: 0.047\n",
      "Epoch 211: Train r2: 0.996, Valid r2: 0.967, Test r2: 0.956, Train mse: 0.004, Valid mse: 0.032, Test mse: 0.044\n",
      "Epoch 221: Train r2: 0.995, Valid r2: 0.963, Test r2: 0.949, Train mse: 0.005, Valid mse: 0.037, Test mse: 0.050\n",
      "Epoch 231: Train r2: 0.996, Valid r2: 0.965, Test r2: 0.951, Train mse: 0.004, Valid mse: 0.035, Test mse: 0.049\n",
      "Epoch 241: Train r2: 0.996, Valid r2: 0.966, Test r2: 0.953, Train mse: 0.004, Valid mse: 0.034, Test mse: 0.047\n",
      "Epoch 251: Train r2: 0.996, Valid r2: 0.968, Test r2: 0.953, Train mse: 0.004, Valid mse: 0.032, Test mse: 0.047\n",
      "Epoch 261: Train r2: 0.997, Valid r2: 0.975, Test r2: 0.958, Train mse: 0.003, Valid mse: 0.025, Test mse: 0.042\n",
      "Epoch 271: Train r2: 0.997, Valid r2: 0.975, Test r2: 0.954, Train mse: 0.003, Valid mse: 0.025, Test mse: 0.046\n",
      "Epoch 281: Train r2: 0.996, Valid r2: 0.964, Test r2: 0.950, Train mse: 0.004, Valid mse: 0.036, Test mse: 0.049\n",
      "Epoch 291: Train r2: 0.998, Valid r2: 0.978, Test r2: 0.958, Train mse: 0.002, Valid mse: 0.022, Test mse: 0.042\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ede182ad6c245b49f54c1732e32003d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train r2: 0.868, Valid r2: 0.518, Test r2: 0.556, Train mse: 0.132, Valid mse: 0.482, Test mse: 0.397\n",
      "Epoch 11: Train r2: 0.990, Valid r2: 0.929, Test r2: 0.889, Train mse: 0.010, Valid mse: 0.069, Test mse: 0.099\n",
      "Epoch 21: Train r2: 0.991, Valid r2: 0.930, Test r2: 0.913, Train mse: 0.009, Valid mse: 0.070, Test mse: 0.078\n",
      "Epoch 31: Train r2: 0.995, Valid r2: 0.958, Test r2: 0.939, Train mse: 0.005, Valid mse: 0.042, Test mse: 0.054\n",
      "Epoch 41: Train r2: 0.992, Valid r2: 0.939, Test r2: 0.936, Train mse: 0.008, Valid mse: 0.061, Test mse: 0.058\n",
      "Epoch 51: Train r2: 0.994, Valid r2: 0.950, Test r2: 0.936, Train mse: 0.006, Valid mse: 0.050, Test mse: 0.057\n",
      "Epoch 61: Train r2: 0.992, Valid r2: 0.939, Test r2: 0.937, Train mse: 0.008, Valid mse: 0.061, Test mse: 0.056\n",
      "Epoch 71: Train r2: 0.996, Valid r2: 0.969, Test r2: 0.949, Train mse: 0.004, Valid mse: 0.030, Test mse: 0.046\n",
      "Epoch 81: Train r2: 0.992, Valid r2: 0.927, Test r2: 0.929, Train mse: 0.008, Valid mse: 0.073, Test mse: 0.063\n",
      "Epoch 91: Train r2: 0.996, Valid r2: 0.966, Test r2: 0.945, Train mse: 0.004, Valid mse: 0.033, Test mse: 0.049\n",
      "Epoch 101: Train r2: 0.995, Valid r2: 0.956, Test r2: 0.942, Train mse: 0.005, Valid mse: 0.044, Test mse: 0.052\n",
      "Epoch 111: Train r2: 0.994, Valid r2: 0.951, Test r2: 0.943, Train mse: 0.006, Valid mse: 0.048, Test mse: 0.051\n",
      "Epoch 121: Train r2: 0.995, Valid r2: 0.957, Test r2: 0.945, Train mse: 0.005, Valid mse: 0.042, Test mse: 0.049\n",
      "Epoch 131: Train r2: 0.997, Valid r2: 0.971, Test r2: 0.952, Train mse: 0.003, Valid mse: 0.029, Test mse: 0.043\n",
      "Epoch 141: Train r2: 0.997, Valid r2: 0.977, Test r2: 0.952, Train mse: 0.003, Valid mse: 0.023, Test mse: 0.043\n",
      "Epoch 151: Train r2: 0.997, Valid r2: 0.969, Test r2: 0.950, Train mse: 0.003, Valid mse: 0.030, Test mse: 0.045\n",
      "Epoch 161: Train r2: 0.998, Valid r2: 0.981, Test r2: 0.955, Train mse: 0.002, Valid mse: 0.018, Test mse: 0.041\n",
      "Epoch 171: Train r2: 0.997, Valid r2: 0.971, Test r2: 0.955, Train mse: 0.003, Valid mse: 0.028, Test mse: 0.041\n",
      "Epoch 181: Train r2: 0.997, Valid r2: 0.968, Test r2: 0.950, Train mse: 0.003, Valid mse: 0.031, Test mse: 0.045\n",
      "Epoch 191: Train r2: 0.997, Valid r2: 0.966, Test r2: 0.947, Train mse: 0.003, Valid mse: 0.034, Test mse: 0.048\n",
      "Epoch 201: Train r2: 0.995, Valid r2: 0.951, Test r2: 0.934, Train mse: 0.005, Valid mse: 0.049, Test mse: 0.059\n",
      "Epoch 211: Train r2: 0.997, Valid r2: 0.972, Test r2: 0.957, Train mse: 0.003, Valid mse: 0.026, Test mse: 0.038\n",
      "Epoch 221: Train r2: 0.997, Valid r2: 0.975, Test r2: 0.952, Train mse: 0.003, Valid mse: 0.025, Test mse: 0.043\n",
      "Epoch 231: Train r2: 0.997, Valid r2: 0.970, Test r2: 0.955, Train mse: 0.003, Valid mse: 0.030, Test mse: 0.040\n",
      "Epoch 241: Train r2: 0.997, Valid r2: 0.969, Test r2: 0.951, Train mse: 0.003, Valid mse: 0.031, Test mse: 0.044\n",
      "Epoch 251: Train r2: 0.998, Valid r2: 0.984, Test r2: 0.957, Train mse: 0.002, Valid mse: 0.016, Test mse: 0.038\n",
      "Epoch 261: Train r2: 0.998, Valid r2: 0.981, Test r2: 0.958, Train mse: 0.002, Valid mse: 0.019, Test mse: 0.038\n",
      "Epoch 271: Train r2: 0.998, Valid r2: 0.977, Test r2: 0.958, Train mse: 0.002, Valid mse: 0.023, Test mse: 0.037\n",
      "Epoch 281: Train r2: 0.997, Valid r2: 0.972, Test r2: 0.952, Train mse: 0.003, Valid mse: 0.028, Test mse: 0.043\n",
      "Epoch 291: Train r2: 0.997, Valid r2: 0.970, Test r2: 0.953, Train mse: 0.003, Valid mse: 0.030, Test mse: 0.042\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "298f8825fa97440790b1fdf0fb5327ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train r2: 0.852, Valid r2: 0.461, Test r2: 0.516, Train mse: 0.148, Valid mse: 0.537, Test mse: 0.498\n",
      "Epoch 11: Train r2: 0.985, Valid r2: 0.899, Test r2: 0.852, Train mse: 0.015, Valid mse: 0.099, Test mse: 0.152\n",
      "Epoch 21: Train r2: 0.987, Valid r2: 0.909, Test r2: 0.891, Train mse: 0.013, Valid mse: 0.089, Test mse: 0.112\n",
      "Epoch 31: Train r2: 0.986, Valid r2: 0.902, Test r2: 0.899, Train mse: 0.014, Valid mse: 0.096, Test mse: 0.104\n",
      "Epoch 41: Train r2: 0.990, Valid r2: 0.931, Test r2: 0.917, Train mse: 0.010, Valid mse: 0.067, Test mse: 0.086\n",
      "Epoch 51: Train r2: 0.989, Valid r2: 0.918, Test r2: 0.914, Train mse: 0.011, Valid mse: 0.082, Test mse: 0.089\n",
      "Epoch 61: Train r2: 0.988, Valid r2: 0.913, Test r2: 0.920, Train mse: 0.012, Valid mse: 0.087, Test mse: 0.082\n",
      "Epoch 71: Train r2: 0.988, Valid r2: 0.922, Test r2: 0.930, Train mse: 0.012, Valid mse: 0.078, Test mse: 0.072\n",
      "Epoch 81: Train r2: 0.991, Valid r2: 0.937, Test r2: 0.933, Train mse: 0.009, Valid mse: 0.063, Test mse: 0.069\n",
      "Epoch 91: Train r2: 0.991, Valid r2: 0.936, Test r2: 0.934, Train mse: 0.009, Valid mse: 0.063, Test mse: 0.068\n",
      "Epoch 101: Train r2: 0.992, Valid r2: 0.937, Test r2: 0.938, Train mse: 0.008, Valid mse: 0.063, Test mse: 0.064\n",
      "Epoch 111: Train r2: 0.990, Valid r2: 0.927, Test r2: 0.928, Train mse: 0.010, Valid mse: 0.072, Test mse: 0.075\n",
      "Epoch 121: Train r2: 0.993, Valid r2: 0.945, Test r2: 0.937, Train mse: 0.007, Valid mse: 0.054, Test mse: 0.064\n",
      "Epoch 131: Train r2: 0.993, Valid r2: 0.945, Test r2: 0.943, Train mse: 0.007, Valid mse: 0.054, Test mse: 0.058\n",
      "Epoch 141: Train r2: 0.990, Valid r2: 0.925, Test r2: 0.932, Train mse: 0.010, Valid mse: 0.074, Test mse: 0.070\n"
     ]
    }
   ],
   "source": [
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter('ignore')\n",
    "    os.environ[\"PYTHONWARNINGS\"] = 'ignore'\n",
    "\n",
    "for i, exp in exp_df.iterrows():\n",
    "    EXP_ID = exp.exp_id\n",
    "    SEED = exp.seed\n",
    "    if exp.torch_dtype == 64:\n",
    "        DTYPE = torch.float64\n",
    "    elif exp.torch_dtype == 32:\n",
    "        DTYPE = torch.float32\n",
    "    N = exp.samples_number\n",
    "    D = exp.features_number\n",
    "    SNR_DB = exp.snr_db\n",
    "    INFORMATIVE_FRAC = exp.informative_frac\n",
    "    NUM_FOLDS = exp.folds_number\n",
    "    INITIALIZATION = exp.initialization\n",
    "    EPOCHS = exp.epochs_number\n",
    "    LEARNING_RATE = exp.learning_rate\n",
    "    \n",
    "    ### Create output folders\n",
    "    os.makedirs(os.path.join('..', 'results', 'multiridge', FILENAME.split('.')[0], 'data'), exist_ok=True)\n",
    "    data_folder = os.path.join('..', 'results', 'multiridge', FILENAME.split('.')[0], 'data')\n",
    "    os.makedirs(os.path.join('..', 'results', 'multiridge', FILENAME.split('.')[0], 'images'), exist_ok=True)\n",
    "    images_folder = os.path.join('..', 'results', 'multiridge', FILENAME.split('.')[0], 'images')\n",
    "    \n",
    "    ### Data generation\n",
    "    train, test, features, target, theta_true = generate_synthetic_dataset(n_samples_train=N, n_samples_test=100000, n_features=D, n_informative=int(D*INFORMATIVE_FRAC),\n",
    "                                                                           snr_db=SNR_DB, random_state=SEED)\n",
    "    check_snr(train, test, features, target, theta_true, snr_db=SNR_DB)\n",
    "\n",
    "    ### MultiRidge optimization\n",
    "    initialization = np.ones(D)*exp.initialization\n",
    "    learning_rate = LinearLR(initial_lr=LEARNING_RATE, decay=0.999)\n",
    "    model = MultiRidge(lambda_vector=initialization, folds=NUM_FOLDS, shuffle=True, random_state=SEED, normalize=True,\n",
    "                       epochs=EPOCHS, learning_rate=learning_rate, scoring={'r2': r2_score, 'mse': mean_squared_error},\n",
    "                       verbose=10, device=DEVICE, dtype=DTYPE)\n",
    "    model.fit(train[features], train[target], eval_set=(test[features], test[target]))\n",
    "    results_dict = {'exp_id': EXP_ID, 'history_df': model.history_df}#, 'history_coef': history_coef}\n",
    "    with open(os.path.join(data_folder, f'{EXP_ID}.pickle'), 'wb') as handle:\n",
    "        pickle.dump(results_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "    ### Plot dashboard\n",
    "    pathfile_mr = os.path.join(images_folder, f'{EXP_ID}')\n",
    "    fig_params = {'train_color': \"#9fc377\", 'test_color': \"#0272a2\", 'valid_color': \"#ca0b03\"}\n",
    "    metric_params = {'metric': 'r2', 'metric_func': r2_score, 'metric_label': '$R^2$'}\n",
    "    plot_monitoring_dashboard_multiridge(train, test, features, target, folds=NUM_FOLDS, model=model, history=model.history_df,\n",
    "                                         fig_params=fig_params, metric_params=metric_params, savefig=pathfile_mr, show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6b755a-f99e-4921-9753-f6dcda2b0c98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
